{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 9: Temporal Features\n",
        "==============================\n",
        "\n",
        "Key Learning Objectives:\n",
        "1. Understand the importance of temporal features\n",
        "2. Learn different techniques for date-based feature engineering\n",
        "3. Create cyclical features for periodic patterns\n",
        "4. Extract time-based trends and patterns"
      ],
      "metadata": {
        "id": "TEf4O6_oEjrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "f3ov8vRdEzyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('loan_applications.csv')"
      ],
      "metadata": {
        "id": "_KwOPVLaE1W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Convert application_date to datetime\n"
      ],
      "metadata": {
        "id": "L5Gt5JHjE-Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Extract Basic Time Components\n",
        "df_temporal['year'] = None\n",
        "df_temporal['month'] = None\n",
        "df_temporal['day'] = None\n",
        "df_temporal['day_of_week'] = None\n",
        "df_temporal['quarter'] = None\n",
        "df_temporal['is_weekend'] = None"
      ],
      "metadata": {
        "id": "G13Gc2t9a4DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize temporal patterns\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "monthly_defaults = df_temporal.groupby('month')['default'].mean()\n",
        "sns.lineplot(x=monthly_defaults.index, y=monthly_defaults.values)\n",
        "plt.title('Default Rate by Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Default Rate')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.boxplot(data=df_temporal, x='day_of_week', y='loan_amount')\n",
        "plt.title('Loan Amount by Day of Week')\n",
        "plt.xlabel('Day of Week (0=Monday)')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "quarterly_volumes = df_temporal.groupby('quarter').size()\n",
        "plt.pie(quarterly_volumes, labels=[f'Q{i}' for i in range(1, 5)],\n",
        "        autopct='%1.1f%%')\n",
        "plt.title('Application Volume by Quarter')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OJBgu62sa-UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-Based Features\n",
        "----------------------\n",
        "Create features based on temporal relationships and patterns."
      ],
      "metadata": {
        "id": "_hLPFVzhbPr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Monthly Patterns\n",
        "monthly_stats = df_temporal.groupby('month').agg({\n",
        "    'loan_amount': ['mean', 'count'],\n",
        "    'default': 'mean'\n",
        "}).round(3)"
      ],
      "metadata": {
        "id": "51-NujU9bnlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Seasonal Indices\n",
        "def calculate_seasonal_index(df, feature, period_col):\n",
        "    return None"
      ],
      "metadata": {
        "id": "WMhi57cYbpdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seasonal_indices = {\n",
        "    'loan_amount': calculate_seasonal_index(df_temporal, 'loan_amount', 'month'),\n",
        "    'default_rate': calculate_seasonal_index(df_temporal, 'default', 'month')\n",
        "}"
      ],
      "metadata": {
        "id": "DcZ5Se-gbquN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize seasonal patterns\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "seasonal_indices['loan_amount'].plot(kind='bar')\n",
        "plt.title('Seasonal Index: Loan Amount')\n",
        "plt.xlabel('Month')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "seasonal_indices['default_rate'].plot(kind='bar')\n",
        "plt.title('Seasonal Index: Default Rate')\n",
        "plt.xlabel('Month')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.heatmap(df_temporal.pivot_table(\n",
        "    index='day_of_week',\n",
        "    columns='month',\n",
        "    values='loan_amount',\n",
        "    aggfunc='mean'\n",
        "), cmap='YlOrRd')\n",
        "plt.title('Loan Amount Patterns\\nby Month and Day of Week')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kGpXDfUmbstL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 10: Aggregating Features\n",
        "=================================\n",
        "\n",
        "\n",
        "Key Learning Objectives:\n",
        "1. Understand different types of aggregations\n",
        "2. Create group-based statistical features\n",
        "3. Implement temporal aggregations\n",
        "4. Evaluate aggregation effectiveness"
      ],
      "metadata": {
        "id": "LRO_B4Lob4Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "6QjYD01jb6nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with interactions\n",
        "df = pd.read_csv('loan_applications.csv')"
      ],
      "metadata": {
        "id": "I_AQdLbsb7-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define groups and metrics for aggregation\n",
        "categorical_groups = ['education', 'occupation', 'city']\n",
        "numerical_features = ['income', 'loan_amount', 'monthly_payment', 'credit_score']\n",
        "df_agg = df.copy()\n",
        "\n",
        "# 1. Basic Statistical Aggregations\n",
        "for group in categorical_groups:\n",
        "    for feature in numerical_features:\n",
        "        # Mean and standard deviation\n",
        "        group_mean = df.groupby(group)[feature].transform('mean')\n",
        "        group_std = df.groupby(group)[feature].transform('std')\n",
        "\n",
        "        # Z-score within group\n",
        "        df_agg[f'{feature}_{group}_zscore'] = (df[feature] - group_mean) / group_std\n",
        "\n",
        "        # Percentile within group\n",
        "        df_agg[f'{feature}_{group}_percentile'] = df.groupby(group)[feature].transform(\n",
        "            lambda x: pd.qcut(x, q=100, labels=False, duplicates='drop')\n",
        "        )"
      ],
      "metadata": {
        "id": "Ml9pWFrYb_rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Ratio to Group Statistics\n",
        "for group in categorical_groups:\n",
        "    for feature in numerical_features:\n",
        "        # Ratio to group mean\n",
        "        group_mean = df.groupby(group)[feature].transform('mean')\n",
        "        df_agg[f'{feature}_{group}_ratio'] = df[feature] / group_mean"
      ],
      "metadata": {
        "id": "o40IbgZTcCcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize group-based aggregations\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.boxplot(data=df_agg, x='education',\n",
        "            y='income_education_zscore')\n",
        "plt.title('Income Z-Score by Education')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(data=df_agg,\n",
        "                x='loan_amount_occupation_percentile',\n",
        "                y='default', hue='occupation')\n",
        "plt.title('Default vs Loan Percentile by Occupation')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.boxplot(data=df_agg, x='city',\n",
        "            y='credit_score_city_ratio')\n",
        "plt.title('Credit Score Ratio by City')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NPhO990dcFAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lecture 11: Handling Imbalanced Datasets\n",
        "=======================================\n",
        "\n",
        "\n",
        "We'll learn four main approaches:\n",
        "1. Understanding and Measuring Imbalance\n",
        "2. Oversampling Techniques (SMOTE)\n",
        "3. Undersampling Strategies\n",
        "4. Combining Methods"
      ],
      "metadata": {
        "id": "1DfIMrNbdSeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n"
      ],
      "metadata": {
        "id": "36uxflS6j0hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our dataset\n",
        "df = pd.read_csv('loan_applications.csv')"
      ],
      "metadata": {
        "id": "-sLGji6Ndfiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant numerical features\n",
        "numerical_features = [\n",
        "    'age', 'employment_length', 'income', 'loan_amount',\n",
        "    'loan_term', 'interest_rate', 'monthly_payment',\n",
        "    'credit_score'\n",
        "]\n",
        "\n",
        "# Handle missing values\n",
        "df[numerical_features] = df[numerical_features].fillna(df[numerical_features].mean())\n",
        "\n",
        "# Prepare features and target\n",
        "X = df[numerical_features]\n",
        "y = df['default']"
      ],
      "metadata": {
        "id": "ij-R91VwjxrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8jjGXJekdk_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class distribution\n",
        "class_counts = df['default'].value_counts()\n",
        "imbalance_ratio = class_counts[0] / class_counts[1]"
      ],
      "metadata": {
        "id": "t6n_60DZdqDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize class imbalance\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "class_counts.plot(kind='bar')\n",
        "plt.title('Class Distribution')\n",
        "plt.xlabel('Default Status')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(class_counts, labels=['Non-Default', 'Default'], autopct='%1.1f%%')\n",
        "plt.title(f'Class Imbalance\\nRatio: {imbalance_ratio:.2f}:1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nIiDs2H0dsw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oversampling with SMOTE\n",
        "-------------------------\n",
        "SMOTE (Synthetic Minority Over-sampling Technique) creates synthetic\n",
        "examples of the minority class."
      ],
      "metadata": {
        "id": "NZOrgd3odwzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print class distribution before SMOTE\n"
      ],
      "metadata": {
        "id": "LpyVGx9ykA3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE\n"
      ],
      "metadata": {
        "id": "mlwGqVEWkAz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature distributions before and after SMOTE\n",
        "def plot_feature_distributions(X_orig, X_smote, y_orig, y_smote, feature_idx):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for label in [0, 1]:\n",
        "        sns.kdeplot(X_orig[y_orig == label, feature_idx],\n",
        "                   label=f\"Class {label}\")\n",
        "    plt.title(\"Original Distribution\")\n",
        "    plt.xlabel(numerical_features[feature_idx])\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for label in [0, 1]:\n",
        "        sns.kdeplot(X_smote[y_smote == label, feature_idx],\n",
        "                   label=f\"Class {label}\")\n",
        "    plt.title(\"After SMOTE\")\n",
        "    plt.xlabel(numerical_features[feature_idx])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fPqQCsYDkAup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot distributions for loan amount and credit score\n",
        "plot_feature_distributions(X_train_scaled, X_train_smote,\n",
        "                         y_train, y_train_smote,\n",
        "                         numerical_features.index('loan_amount'))\n",
        "plot_feature_distributions(X_train_scaled, X_train_smote,\n",
        "                         y_train, y_train_smote,\n",
        "                         numerical_features.index('credit_score'))"
      ],
      "metadata": {
        "id": "MPvHOYZDd0GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Undersampling Strategies\n",
        "--------------------------\n",
        "Reduce the majority class to balance the dataset."
      ],
      "metadata": {
        "id": "f4d_HpV8d_2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply random undersampling\n"
      ],
      "metadata": {
        "id": "8NY9PHsyeCmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Lecture 13: Handling High Cardinality Features\n",
        "==============================================\n",
        "\n",
        "\n",
        "\n",
        "Key Learning Objectives:\n",
        "1. Understand the challenges of high cardinality features\n",
        "2. Learn different encoding strategies\n",
        "3. Implement frequency-based encoding\n",
        "4. Apply target-based encoding\n",
        "\n"
      ],
      "metadata": {
        "id": "gFBhwDqXgkmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
        "from scipy.stats import chi2_contingency"
      ],
      "metadata": {
        "id": "09__b9O2gqfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('loan_applications.csv')"
      ],
      "metadata": {
        "id": "tMfV4Sl8gt4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical columns and their cardinality\n",
        "categorical_columns = ['city', 'occupation', 'education', 'gender']\n",
        "cardinality_stats = pd.DataFrame({\n",
        "    'Feature': categorical_columns,\n",
        "    'Unique_Values': [df[col].nunique() for col in categorical_columns],\n",
        "    'Unique_Ratio': [df[col].nunique() / len(df) for col in categorical_columns]\n",
        "}).sort_values('Unique_Values', ascending=False)\n",
        "\n",
        "print(\"Cardinality Analysis:\")\n",
        "print(cardinality_stats)"
      ],
      "metadata": {
        "id": "vfSenVCxgxvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize cardinality\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(cardinality_stats['Feature'], cardinality_stats['Unique_Values'])\n",
        "plt.title('Number of Unique Values by Feature')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Number of Unique Values')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kOTzz4Uwgzd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate and plot frequency encoding\n",
        "def apply_frequency_encoding(df, feature):\n",
        "    return None"
      ],
      "metadata": {
        "id": "TrQncb8qg25S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply frequency encoding to city and occupation\n",
        "df['city_freq'] = apply_frequency_encoding(df, 'city')\n",
        "df['occupation_freq'] = apply_frequency_encoding(df, 'occupation')"
      ],
      "metadata": {
        "id": "Zkj5jPIdg4pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Rare Categories\n",
        "--------------------------\n",
        "Group rare categories to reduce cardinality while preserving information."
      ],
      "metadata": {
        "id": "wdEyg70sh4FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_rare_categories(df, feature, min_freq=0.01):\n",
        "    return None"
      ],
      "metadata": {
        "id": "Sp-cAhZsh8Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group rare categories\n",
        "df['city_grouped'] = group_rare_categories(df, 'city', min_freq=0.02)\n",
        "df['occupation_grouped'] = group_rare_categories(df, 'occupation', min_freq=0.05)"
      ],
      "metadata": {
        "id": "A2SLUpg9h9w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 14: Feature Selection Techniques\n",
        "=====================================\n",
        "\n",
        "Key Learning Objectives:\n",
        "1. Understand different feature selection approaches\n",
        "2. Apply correlation-based selection\n",
        "3. Implement model-based selection\n",
        "4. Compare feature importance across methods"
      ],
      "metadata": {
        "id": "YwbQHrUJi2Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "uu6JhqUGi86b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with encoded features\n",
        "df = pd.read_csv('loan_applications.csv')"
      ],
      "metadata": {
        "id": "IZZCPZ1yjAns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numerical features\n",
        "numerical_features = [\n",
        "    'age', 'employment_length', 'income', 'loan_amount',\n",
        "    'loan_term', 'interest_rate', 'monthly_payment',\n",
        "    'credit_score', 'existing_loans'\n",
        "]"
      ],
      "metadata": {
        "id": "IydUJL7ejDjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlations = None"
      ],
      "metadata": {
        "id": "QoNioaMOjEsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize correlations\n",
        "plt.figure(figsize=(12, 6))\n",
        "correlations.drop('default').plot(kind='bar')\n",
        "plt.title('Feature Correlations with Default')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Correlation Coefficient')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oyE8hYnhjF47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mutual Information Analysis\n",
        "-----------------------------\n",
        "Use mutual information to capture non-linear relationships."
      ],
      "metadata": {
        "id": "O-bTbxgKjHsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features for mutual information\n",
        "X = df[numerical_features]\n",
        "y = df['default']\n",
        "\n",
        "# Handle missing values\n",
        "X = X.fillna(X.mean())"
      ],
      "metadata": {
        "id": "vyOR0_K3jLHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mutual information scores\n"
      ],
      "metadata": {
        "id": "CbUQmVvujMTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize mutual information scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "mi_series.plot(kind='bar')\n",
        "plt.title('Mutual Information Scores')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Mutual Information')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8O080MVfjNme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model-based Feature Importance\n",
        "--------------------------------\n",
        "Use Random Forest to evaluate feature importance."
      ],
      "metadata": {
        "id": "6w9wF5osjPYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare all features (numerical + encoded)\n",
        "all_features = numerical_features"
      ],
      "metadata": {
        "id": "rtImqqKhjSGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = df[all_features].fillna(df[all_features].mean())\n",
        "y = df['default']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_all)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_scaled, y)"
      ],
      "metadata": {
        "id": "bWKg5ianjUME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get feature importance\n",
        "importance = pd.DataFrame({\n",
        "    'Feature': all_features,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(importance['Feature'], importance['Importance'])\n",
        "plt.title('Random Forest Feature Importance')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5l-y9zNRjYMW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}